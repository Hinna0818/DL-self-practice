{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "层和块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 定义一个MLP块（包含256个单元的隐藏层和一个10维输出层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.9554e-01, -6.8164e-01, -5.4824e-01, -1.1032e+00, -3.2836e-02,\n",
       "         -9.5626e-01, -2.5210e-01, -5.4677e-01, -7.6672e-01, -1.8748e+00,\n",
       "          1.1100e-01, -8.3585e-03,  6.1015e-02,  4.7751e-01, -1.7325e+00,\n",
       "         -2.5108e-01, -2.8593e-01, -3.9150e-01, -3.9549e-01, -2.6752e-01],\n",
       "        [ 5.5885e-01,  1.4754e-03,  7.2378e-01, -2.3723e-01, -1.5148e-01,\n",
       "          1.3982e+00, -1.3631e+00,  7.8454e-02, -5.1196e-01,  1.1061e+00,\n",
       "          6.6938e-01, -6.7595e-02, -4.0797e-01,  2.6570e-01, -1.1499e+00,\n",
       "         -3.8921e-01,  4.2028e-01,  1.5264e+00, -2.5360e-01,  6.5580e-03]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 随机生成一个2x10的张量\n",
    "X = torch.randn(2, 20)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 从头编写一个MLP类（Module子类）\n",
    "class MLP(nn.Module):\n",
    "    ## 初始化\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "    \n",
    "    ## 定义前向传播函数\n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3837, -0.1129, -0.0970, -0.1217,  0.1737, -0.2268,  0.0224,  0.2441,\n",
       "         -0.1296, -0.0910],\n",
       "        [-0.2863, -0.1819, -0.1009, -0.0800, -0.1360,  0.0827, -0.1208,  0.0706,\n",
       "         -0.0573,  0.0006]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 创建MLP实例\n",
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MLP(\n",
      "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(net.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 定义一个顺序块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            self._modules[str(idx)] = module\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2064,  0.2374,  0.0619,  0.0460, -0.1093, -0.1236, -0.0008, -0.2300,\n",
       "         -0.0098, -0.2635],\n",
       "        [-0.0696,  0.2376,  0.3117, -0.2089, -0.1829, -0.1356, -0.0555, -0.0578,\n",
       "          0.1043,  0.1046]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2248, -0.2591,  0.0273,  0.1665,  0.2015,  0.3734, -0.1806,  0.1012,\n",
       "          0.1398,  0.2632],\n",
       "        [-0.0628, -0.2370,  0.0587, -0.1741,  0.0645,  0.1949, -0.1770, -0.1823,\n",
       "         -0.3528, -0.0610]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 同样也可以使用Sequential类\n",
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 个性化设置块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ## 随机生成权重值，且不设置梯度，即不更新权重参数\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad = False)\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "    \n",
    "    def forward(self , X):\n",
    "        X = self.linear(X)\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        X = self.linear(X)\n",
    "\n",
    "        ## 控制流\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0209, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
